When learning the expected value of a bandit, maintiaining a current expected value and updating by new observations weighted by 1/n will learn an time-unbiased mean. Does this apply to neural networks?

It seems that the theoretically optimal dynamic learning rate converges much quicker, but to a noisier and higher loss than the constant learning rate.

![Training Losses SGD](path/to/training_losses_sgd.png)